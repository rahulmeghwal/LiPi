{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Roberta + LSTM + crf.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e0b8624abc584f84a3f15315e30bd82b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_56067dfaf70048088f20006537d766ca",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1295c6c427614857a45c77298bf185fa",
              "IPY_MODEL_5f4415a42d944b4e9cc95a085b0fd93d",
              "IPY_MODEL_bb8826407aee49bb8b5c87c578bf244c"
            ]
          }
        },
        "56067dfaf70048088f20006537d766ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1295c6c427614857a45c77298bf185fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f067d1608f64bceb8ffd8171450ba66",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b2372e6ff1447cc9e9b46697fff4f4c"
          }
        },
        "5f4415a42d944b4e9cc95a085b0fd93d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f5c2912b35ab4cd087d967d7461856bc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c41833a10d13446c92958dbe7477592d"
          }
        },
        "bb8826407aee49bb8b5c87c578bf244c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_62b4f77a896e4d11ae9d79e439bee836",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 878k/878k [00:00&lt;00:00, 697kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_51e273f7b5f7470c899ba9d626a84389"
          }
        },
        "6f067d1608f64bceb8ffd8171450ba66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b2372e6ff1447cc9e9b46697fff4f4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5c2912b35ab4cd087d967d7461856bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c41833a10d13446c92958dbe7477592d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62b4f77a896e4d11ae9d79e439bee836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "51e273f7b5f7470c899ba9d626a84389": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b77a6dcf46ed46c8b956d9412efdb718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cbf06083a63f49e0a7cbffc3b6d7baa4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8b3ab7268a504fd18b3ac3dc67355d07",
              "IPY_MODEL_0f8e1aa16c9c4933a0b5b383df7eab38",
              "IPY_MODEL_15b4d978906f4026b9aff3f80b923db0"
            ]
          }
        },
        "cbf06083a63f49e0a7cbffc3b6d7baa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b3ab7268a504fd18b3ac3dc67355d07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ee0cd3d4aeb746ebb18ba7d6932f8b14",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cddf866e824d4524b5ea6995c52dc5f7"
          }
        },
        "0f8e1aa16c9c4933a0b5b383df7eab38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9fb457a5e2f74d0e84650052460da7ff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6eef28ac9ab747f08ac7e6d532745f65"
          }
        },
        "15b4d978906f4026b9aff3f80b923db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d640a48dd4bc4a9b883c109af785f793",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 446k/446k [00:00&lt;00:00, 632kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83a786a948334619b1d9277f4a0360c5"
          }
        },
        "ee0cd3d4aeb746ebb18ba7d6932f8b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cddf866e824d4524b5ea6995c52dc5f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9fb457a5e2f74d0e84650052460da7ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6eef28ac9ab747f08ac7e6d532745f65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d640a48dd4bc4a9b883c109af785f793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83a786a948334619b1d9277f4a0360c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f342d9ef4a934b7ab1c3be20e2b881c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_64df250ee62f4a959e47d77756d33d66",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c14ddcf73985407882933a1da3fb23ab",
              "IPY_MODEL_530fd3c2f7a84cd087d41c429617fc59",
              "IPY_MODEL_dea37058559a4bca84af2604143c07c6"
            ]
          }
        },
        "64df250ee62f4a959e47d77756d33d66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c14ddcf73985407882933a1da3fb23ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_867318709ff9476293b6619df08131b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_81eecd03204f4cc49c494e3715ed683d"
          }
        },
        "530fd3c2f7a84cd087d41c429617fc59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e489837fd3d1401a9308583df5807214",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355863,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355863,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a8d1cb699c74ed587f322940fbc087f"
          }
        },
        "dea37058559a4bca84af2604143c07c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c37676de53f247bfb000ad746434fe39",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.29M/1.29M [00:01&lt;00:00, 1.19MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a00148a399f647acbcdbe2ae6a404114"
          }
        },
        "867318709ff9476293b6619df08131b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "81eecd03204f4cc49c494e3715ed683d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e489837fd3d1401a9308583df5807214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a8d1cb699c74ed587f322940fbc087f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c37676de53f247bfb000ad746434fe39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a00148a399f647acbcdbe2ae6a404114": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a544a91c24947b39fb3b9da16bd18bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bedd90773b534f3ab1980cd57e8cf3dd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7ee89de091fa4669a94be61d362bb249",
              "IPY_MODEL_5b817fa5a8a94c0dbfbdfd1b4e9a66dc",
              "IPY_MODEL_4299c0cd96154bcd87cc41fbd8a825d2"
            ]
          }
        },
        "bedd90773b534f3ab1980cd57e8cf3dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ee89de091fa4669a94be61d362bb249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_267e00b0bc2840e9abf6c74a3eb1fae5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6da58e1186e9468ca49b40980c03d50b"
          }
        },
        "5b817fa5a8a94c0dbfbdfd1b4e9a66dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d2bd7a7322d5449cbd932381869334de",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7c985fb35464b889418bddf8e442033"
          }
        },
        "4299c0cd96154bcd87cc41fbd8a825d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d57aefebc9314921882682e5e40f6e76",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:00&lt;00:00, 13.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2724c64ebb3d42deb938fba1b599cf70"
          }
        },
        "267e00b0bc2840e9abf6c74a3eb1fae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6da58e1186e9468ca49b40980c03d50b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2bd7a7322d5449cbd932381869334de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7c985fb35464b889418bddf8e442033": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d57aefebc9314921882682e5e40f6e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2724c64ebb3d42deb938fba1b599cf70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49e27de49ef14e6f96403e1e8443c770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fb20f4d75cbf422ab5230f01443ddbe7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_429fb63d0f0245e2896513a20c57ab17",
              "IPY_MODEL_58bead0d77764c0eb4caaaa401dcc4dd",
              "IPY_MODEL_ca4ec6d9598746f2bcf03f6f505d15a5"
            ]
          }
        },
        "fb20f4d75cbf422ab5230f01443ddbe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "429fb63d0f0245e2896513a20c57ab17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7eed63001acf4a0cbccf423facda5e32",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_36733087ecfb417b9532d2e111366c8a"
          }
        },
        "58bead0d77764c0eb4caaaa401dcc4dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a6c10b28c501455c908a7ca10865e512",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 657434796,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 657434796,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_24a5a5d581c047c2a89a8a3d59d1d966"
          }
        },
        "ca4ec6d9598746f2bcf03f6f505d15a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_699d813cd6e04e2cb8333abce7582bd6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 627M/627M [00:21&lt;00:00, 34.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3dee3ba038694fae86c9baf6ca7d24c4"
          }
        },
        "7eed63001acf4a0cbccf423facda5e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "36733087ecfb417b9532d2e111366c8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a6c10b28c501455c908a7ca10865e512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "24a5a5d581c047c2a89a8a3d59d1d966": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "699d813cd6e04e2cb8333abce7582bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3dee3ba038694fae86c9baf6ca7d24c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulmeghwal/LiPi/blob/master/Roberta_%2B_LSTM_%2B_crf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d617qgDGLsCm",
        "outputId": "b783a582-13b8-4413-b82f-943232873379"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkY6Pa14-uSW"
      },
      "source": [
        "!cp \"/content/drive/My Drive/tsd_test.csv\" \"./toxic_span_practice.csv\"\n",
        "!cp \"/content/drive/My Drive/tsd_train.csv\" \"./toxic_span_train.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GK9vjlbznhTZ",
        "outputId": "d5982c89-a01d-4ebe-b932-5ccc928336c3"
      },
      "source": [
        "!pip install tensorflow==2.3.0\n",
        "!pip install stanza\n",
        "!pip install transformers\n",
        "!pip install tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.3.0 in /usr/local/lib/python3.7/dist-packages (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.37.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.1.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.18.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.2.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (2.10.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (2.7.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.42.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.13.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (3.3.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (2.3.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.1.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.8.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.3.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.1.1)\n",
            "Requirement already satisfied: stanza in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (from stanza) (1.6.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.18.5)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.10.0+cu111)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from stanza) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (3.10.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.15.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZcqPZAZbhEB"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import json\n",
        "import stanza\n",
        "from tensorflow.keras import *\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import *\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import TFRobertaModel,RobertaTokenizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opPxhbPHPQoZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bec0b80b-1901-4562-b459-f9dbd92727fe"
      },
      "source": [
        "test_set = pd.read_csv(\"toxic_span_practice.csv\")\n",
        "test_set['spans'] = test_set['spans'].apply(lambda x : json.loads(x))\n",
        "train_set = pd.read_csv(\"toxic_span_train.csv\")\n",
        "train_set['spans'] = train_set['spans'].apply(lambda x : json.loads(x))\n",
        "toxic_span_dataset = test_set.append(train_set,ignore_index=True)\n",
        "toxic_span_dataset['text'] = toxic_span_dataset['text'].apply(lambda x : x.lower())\n",
        "print(toxic_span_dataset)\n",
        "\n",
        "\n",
        "### Char CNN Processing\n",
        "\n",
        "tk=Tokenizer(num_words=None,char_level=True,oov_token='unk')\n",
        "tk.fit_on_texts(toxic_span_dataset['text'])\n",
        "print(tk.word_index)\n",
        "charcnntext=tk.texts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  spans                                               text\n",
            "0     [84, 85, 86, 87, 88, 89, 90, 91, 133, 134, 135...  that's right. they are not normal. and i am st...\n",
            "1                              [81, 82, 83, 84, 85, 86]  \"watch people die from taking away their healt...\n",
            "2                                                    []  tens years ago i contacted the pdr and suggest...\n",
            "3                                                    []  the parallels between the anc and the sicilian...\n",
            "4                                                    []  intel community: ‘how can we work for a presid...\n",
            "...                                                 ...                                                ...\n",
            "9934                                     [8, 9, 10, 11]                             another fool pipes in.\n",
            "9935  [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 5...  so if a restaurant owner puts up a sign saying...\n",
            "9936  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  any faith that can't stand up to logic and rea...\n",
            "9937                            [5, 6, 7, 8, 9, 10, 11]  this idiotic. use the surplus to pay down the ...\n",
            "9938  [106, 107, 108, 109, 110, 169, 170, 171, 172, ...  who is this \"we\" of which you speak? are you r...\n",
            "\n",
            "[9939 rows x 2 columns]\n",
            "{'unk': 1, ' ': 2, 'e': 3, 't': 4, 'o': 5, 'a': 6, 'i': 7, 's': 8, 'n': 9, 'r': 10, 'h': 11, 'l': 12, 'd': 13, 'u': 14, 'c': 15, 'm': 16, 'y': 17, 'p': 18, 'g': 19, 'w': 20, '.': 21, 'f': 22, 'b': 23, 'v': 24, 'k': 25, ',': 26, \"'\": 27, '\\n': 28, '\"': 29, '-': 30, 'j': 31, '!': 32, '?': 33, 'x': 34, 'z': 35, '0': 36, 'q': 37, '1': 38, ')': 39, '/': 40, '(': 41, '2': 42, ':': 43, '*': 44, '5': 45, '3': 46, '4': 47, ';': 48, '9': 49, '$': 50, '’': 51, '6': 52, '8': 53, '&': 54, '7': 55, '%': 56, '”': 57, '“': 58, '_': 59, '=': 60, '#': 61, '…': 62, '@': 63, '>': 64, '🆘': 65, '[': 66, ']': 67, '+': 68, '▀': 69, '—': 70, '`': 71, '️': 72, '–': 73, '☠': 74, '💀': 75, '~': 76, '‘': 77, '^': 78, '·': 79, '<': 80, '💨': 81, '🔥': 82, '☭': 83, '💥': 84, '✭': 85, '\\u200b': 86, '•': 87, '\\xa0': 88, '―': 89, '«': 90, '»': 91, 'é': 92, '😂': 93, 'ʻ': 94, '™': 95, '😁': 96, '😜': 97, 'ü': 98, '😱': 99, '⚽': 100, '⚾': 101, '{': 102, '👎': 103, '\\\\': 104, 'ˈ': 105, '͞': 106, '¬': 107, '😕': 108, '🍊': 109, '😀': 110, '😄': 111, '´': 112, '\\t': 113, '}': 114, '😊': 115, 'ê': 116, '😈': 117, '\\x7f': 118, '😡': 119, '🙄': 120, '😆': 121, '\\u2004': 122, 'ó': 123, '😉': 124, '😵': 125, '😅': 126, 'ï': 127, '😞': 128, '🤥': 129, '😬': 130, '☹': 131}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I07cu0iEor7X"
      },
      "source": [
        "def createNEROutputs(texts,spans,max_length,tokenizer):\n",
        "    outputs = []\n",
        "    for text,span in zip(texts,spans):\n",
        "        output = np.zeros(max_length*3,dtype=np.float).reshape((max_length,3))\n",
        "        tokens = tokenizer.tokenize(text)[:max_length]\n",
        "        length = 0\n",
        "        start = True\n",
        "        for i in range(len(tokens),max_length):\n",
        "            output[i,0] = 1.0\n",
        "        for index,token in enumerate(tokens):\n",
        "            sub = True\n",
        "            if \"Ġ\" in token:\n",
        "                sub = False\n",
        "                token = token[1:]\n",
        "            if not start:\n",
        "                next_index = text[length:].find(token)\n",
        "                if next_index == 0:\n",
        "                    sub = True\n",
        "                length += next_index\n",
        "            # if length in span and not sub:\n",
        "            #     output[index,2] = 1.0\n",
        "            #     output[index,0] = 0.0\n",
        "            if length in span:\n",
        "                output[index,2] = 1.0\n",
        "                output[index,0] = 0.0\n",
        "            else:\n",
        "                output[index,1] = 1.0\n",
        "                output[index,0] = 0.0\n",
        "            length += len(token)\n",
        "            start = False\n",
        "        outputs.append(output)\n",
        "    return np.array(outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbejXea8fbTo"
      },
      "source": [
        "def NERGetIndicesSingleText(outputs,text,tokenizer):\n",
        "    outputs = tf.argmax(outputs,axis=-1)\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    index = 0\n",
        "    indexes = []\n",
        "    sub = False\n",
        "    prev = False\n",
        "    for token,output in zip(tokens,outputs):\n",
        "        if token[0] == \"Ġ\":\n",
        "            token = token[1:]\n",
        "            sub = False\n",
        "        elif token.isalpha():\n",
        "            sub = True\n",
        "        else:\n",
        "            sub = False\n",
        "        temp_index = text[index:].find(token)\n",
        "        temp_start = index+temp_index\n",
        "        if output == 2 or (sub and prev and output != 0):\n",
        "            prev = True\n",
        "            indexes = indexes + list(range(temp_start,temp_start+len(token)))\n",
        "        else:\n",
        "            prev = False\n",
        "        index = temp_start+len(token)\n",
        "    return np.array(indexes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REsioW8lqyhT"
      },
      "source": [
        "def createIndicesForNERModel(predicts,texts,tokenizer):\n",
        "    outputs = []\n",
        "    for text,pred in zip(texts,predicts):\n",
        "         indices = NERGetIndicesSingleText(pred,text,tokenizer)\n",
        "         outputs.append(indices)\n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjTYF4wQ_-Rg"
      },
      "source": [
        "def f1(preds,trues):\n",
        "    if len(trues) == 0:\n",
        "        return 1. if len(preds) == 0 else 0.\n",
        "    if len(preds) == 0:\n",
        "        return 0.\n",
        "    predictions_set = set(preds)\n",
        "    gold_set = set(trues)\n",
        "    nom = 2 * len(predictions_set.intersection(gold_set))\n",
        "    denom = len(predictions_set) + len(gold_set)\n",
        "    return float(nom)/float(denom)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlzBi7ZyAMsP"
      },
      "source": [
        "def avg_f1(preds,trues):\n",
        "    avg_f1_total = 0.0\n",
        "    for pred,true in zip(preds,trues):\n",
        "        avg_f1_total += f1(pred,true)\n",
        "    return avg_f1_total/len(preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5bPVXNfC_gA"
      },
      "source": [
        "class F1Metric(callbacks.Callback):\n",
        "    def __init__(self,inputs,labels,spans,texts,test=True):\n",
        "        self.inputs = inputs\n",
        "        self.spans = spans\n",
        "        self.tokenizer = tokenizer\n",
        "        self.texts = texts\n",
        "        self.test = test\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        preds = self.model.predict(self.inputs,verbose=0)\n",
        "        indices = createIndicesForNERModel(preds,texts,tokenizer)\n",
        "        f1 = avg_f1(indices,self.spans)\n",
        "        if self.test:\n",
        "            print()\n",
        "            print(\"test f1 = \"+str(f1))\n",
        "        else:\n",
        "            print()\n",
        "            print(\"train f1 = \"+str(f1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWH-LpFvhys1"
      },
      "source": [
        "def createInputForNER(texts,max_length,tokenizer):\n",
        "    input_length = []\n",
        "    for text in texts:\n",
        "        input_length.append(min(max_length,len(tokenizer.tokenize(text))))\n",
        "    tokens = tokenizer(texts,padding=\"max_length\",max_length=max_length,return_tensors=\"tf\",truncation=True)\n",
        "    data = [np.array(tokens['input_ids']),np.array(tokens['attention_mask']),np.array(input_length)]\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sd7ByGjPhP7"
      },
      "source": [
        "# CRF Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhuwwqF2ABZP",
        "outputId": "211b58ef-07ec-4bc1-df7c-bffbde147b57"
      },
      "source": [
        "#https://github.com/Hironsan/keras-crf-layer/blob/master/crf.py\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "try:\n",
        "    from tensorflow.contrib.crf import crf_decode\n",
        "except ImportError:\n",
        "    from tensorflow.python.framework import dtypes\n",
        "    from tensorflow.python.ops import array_ops, gen_array_ops, math_ops, rnn, rnn_cell\n",
        "\n",
        "\n",
        "    class CrfDecodeForwardRnnCell(rnn_cell.RNNCell):\n",
        "        def __init__(self, transition_params):\n",
        "            self._transition_params = array_ops.expand_dims(transition_params, 0)\n",
        "            self._num_tags = transition_params.get_shape()[0]\n",
        "\n",
        "        @property\n",
        "        def state_size(self):\n",
        "            return self._num_tags\n",
        "\n",
        "        @property\n",
        "        def output_size(self):\n",
        "            return self._num_tags\n",
        "\n",
        "        def __call__(self, inputs, state, scope=None):\n",
        "            state = array_ops.expand_dims(state, 2)  # [B, O, 1]\n",
        "            transition_scores = state + self._transition_params  # [B, O, O]\n",
        "            new_state = inputs + math_ops.reduce_max(transition_scores, [1])  # [B, O]\n",
        "            backpointers = math_ops.argmax(transition_scores, 1)\n",
        "            backpointers = math_ops.cast(backpointers, dtype=dtypes.int32)  # [B, O]\n",
        "            return backpointers, new_state\n",
        "\n",
        "\n",
        "    class CrfDecodeBackwardRnnCell(rnn_cell.RNNCell):\n",
        "        def __init__(self, num_tags):\n",
        "            self._num_tags = num_tags\n",
        "\n",
        "        @property\n",
        "        def state_size(self):\n",
        "            return 1\n",
        "\n",
        "        @property\n",
        "        def output_size(self):\n",
        "            return 1\n",
        "\n",
        "        def __call__(self, inputs, state, scope=None):\n",
        "            state = array_ops.squeeze(state, axis=[1])  # [B]\n",
        "            batch_size = array_ops.shape(inputs)[0]\n",
        "            b_indices = math_ops.range(batch_size)  # [B]\n",
        "            indices = array_ops.stack([b_indices, state], axis=1)  # [B, 2]\n",
        "            new_tags = array_ops.expand_dims(\n",
        "                gen_array_ops.gather_nd(inputs, indices),  # [B]\n",
        "                axis=-1)  # [B, 1]\n",
        "\n",
        "            return new_tags, new_tags\n",
        "\n",
        "\n",
        "    def crf_decode(potentials, transition_params, sequence_length):\n",
        "        num_tags = potentials.get_shape()[2]\n",
        "\n",
        "        # Computes forward decoding. Get last score and backpointers.\n",
        "        crf_fwd_cell = CrfDecodeForwardRnnCell(transition_params)\n",
        "        initial_state = array_ops.slice(potentials, [0, 0, 0], [-1, 1, -1])\n",
        "        initial_state = array_ops.squeeze(initial_state, axis=[1])  # [B, O]\n",
        "        inputs = array_ops.slice(potentials, [0, 1, 0], [-1, -1, -1])  # [B, T-1, O]\n",
        "        backpointers, last_score = rnn.dynamic_rnn(\n",
        "            crf_fwd_cell,\n",
        "            inputs=inputs,\n",
        "            sequence_length=sequence_length - 1,\n",
        "            initial_state=initial_state,\n",
        "            time_major=False,\n",
        "            dtype=dtypes.int32)  # [B, T - 1, O], [B, O]\n",
        "        backpointers = gen_array_ops.reverse_sequence(backpointers, sequence_length - 1, seq_dim=1)  # [B, T-1, O]\n",
        "\n",
        "        # Computes backward decoding. Extract tag indices from backpointers.\n",
        "        crf_bwd_cell = CrfDecodeBackwardRnnCell(num_tags)\n",
        "        initial_state = math_ops.cast(math_ops.argmax(last_score, axis=1), dtype=dtypes.int32)  # [B]\n",
        "        initial_state = array_ops.expand_dims(initial_state, axis=-1)  # [B, 1]\n",
        "        decode_tags, _ = rnn.dynamic_rnn(\n",
        "            crf_bwd_cell,\n",
        "            inputs=backpointers,\n",
        "            sequence_length=sequence_length - 1,\n",
        "            initial_state=initial_state,\n",
        "            time_major=False,\n",
        "            dtype=dtypes.int32)  # [B, T - 1, 1]\n",
        "        decode_tags = array_ops.squeeze(decode_tags, axis=[2])  # [B, T - 1]\n",
        "        decode_tags = array_ops.concat([initial_state, decode_tags], axis=1)  # [B, T]\n",
        "        decode_tags = gen_array_ops.reverse_sequence(decode_tags, sequence_length, seq_dim=1)  # [B, T]\n",
        "\n",
        "        best_score = math_ops.reduce_max(last_score, axis=1)  # [B]\n",
        "        return decode_tags, best_score\n",
        "\n",
        "\n",
        "class CRFLayer(Layer):\n",
        "\n",
        "    def __init__(self, transition_params=None, **kwargs):\n",
        "        super(CRFLayer, self).__init__(**kwargs)\n",
        "        self.transition_params = transition_params\n",
        "        self.input_spec = [InputSpec(ndim=3), InputSpec(ndim=2)]\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        assert input_shape and len(input_shape[0]) == 3\n",
        "\n",
        "        return input_shape[0]\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 2\n",
        "        assert len(input_shape[0]) == 3\n",
        "        assert len(input_shape[1]) == 2\n",
        "        n_steps = input_shape[0][1]\n",
        "        n_classes = input_shape[0][2]\n",
        "        assert n_steps is None or n_steps >= 2\n",
        "\n",
        "        self.transition_params = self.add_weight(shape=(n_classes, n_classes),\n",
        "                                                 initializer='uniform',\n",
        "                                                 name='transition')\n",
        "        self.input_spec = [InputSpec(dtype=K.floatx(), shape=(None, n_steps, n_classes)),\n",
        "                           InputSpec(dtype='int32', shape=(None, 1))]\n",
        "        self.built = True\n",
        "\n",
        "    def viterbi_decode(self, potentials, sequence_length):\n",
        "        decode_tags, best_score = crf_decode(potentials, self.transition_params, sequence_length)\n",
        "        return decode_tags\n",
        "\n",
        "    def call(self, inputs, mask=None, **kwargs):\n",
        "        inputs, sequence_lengths = inputs\n",
        "        self.sequence_lengths = K.flatten(sequence_lengths)\n",
        "        y_pred = self.viterbi_decode(inputs, self.sequence_lengths)\n",
        "        nb_classes = self.input_spec[0].shape[2]\n",
        "        y_pred_one_hot = K.one_hot(y_pred, nb_classes)\n",
        "\n",
        "        return K.in_train_phase(inputs, y_pred_one_hot)\n",
        "\n",
        "    def loss(self, y_true, y_pred):\n",
        "        y_true = K.cast(K.argmax(y_true, axis=-1), dtype='int32')\n",
        "        log_likelihood, self.transition_params = tfa.text.crf.crf_log_likelihood(\n",
        "            y_pred, y_true, self.sequence_lengths, self.transition_params)\n",
        "        loss = tf.reduce_mean(-log_likelihood)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'transition_params': K.eval(self.transition_params),\n",
        "        }\n",
        "        base_config = super(CRFLayer, self).get_config()\n",
        "\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "def create_custom_objects():\n",
        "    instanceHolder = {'instance': None}\n",
        "\n",
        "    class ClassWrapper(CRFLayer):\n",
        "        def __init__(self, *args, **kwargs):\n",
        "            instanceHolder['instance'] = self\n",
        "            super(ClassWrapper, self).__init__(*args, **kwargs)\n",
        "\n",
        "    def loss(*args):\n",
        "        method = getattr(instanceHolder['instance'], 'loss')\n",
        "        return method(*args)\n",
        "\n",
        "    return {'CRFLayer': ClassWrapper, 'loss': loss}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.5.0 and strictly below 2.8.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.3.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  UserWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqeMTLB0bRNv"
      },
      "source": [
        "# NER model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHiNwUDqyugU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "e0b8624abc584f84a3f15315e30bd82b",
            "56067dfaf70048088f20006537d766ca",
            "1295c6c427614857a45c77298bf185fa",
            "5f4415a42d944b4e9cc95a085b0fd93d",
            "bb8826407aee49bb8b5c87c578bf244c",
            "6f067d1608f64bceb8ffd8171450ba66",
            "0b2372e6ff1447cc9e9b46697fff4f4c",
            "f5c2912b35ab4cd087d967d7461856bc",
            "c41833a10d13446c92958dbe7477592d",
            "62b4f77a896e4d11ae9d79e439bee836",
            "51e273f7b5f7470c899ba9d626a84389",
            "b77a6dcf46ed46c8b956d9412efdb718",
            "cbf06083a63f49e0a7cbffc3b6d7baa4",
            "8b3ab7268a504fd18b3ac3dc67355d07",
            "0f8e1aa16c9c4933a0b5b383df7eab38",
            "15b4d978906f4026b9aff3f80b923db0",
            "ee0cd3d4aeb746ebb18ba7d6932f8b14",
            "cddf866e824d4524b5ea6995c52dc5f7",
            "9fb457a5e2f74d0e84650052460da7ff",
            "6eef28ac9ab747f08ac7e6d532745f65",
            "d640a48dd4bc4a9b883c109af785f793",
            "83a786a948334619b1d9277f4a0360c5",
            "f342d9ef4a934b7ab1c3be20e2b881c9",
            "64df250ee62f4a959e47d77756d33d66",
            "c14ddcf73985407882933a1da3fb23ab",
            "530fd3c2f7a84cd087d41c429617fc59",
            "dea37058559a4bca84af2604143c07c6",
            "867318709ff9476293b6619df08131b2",
            "81eecd03204f4cc49c494e3715ed683d",
            "e489837fd3d1401a9308583df5807214",
            "1a8d1cb699c74ed587f322940fbc087f",
            "c37676de53f247bfb000ad746434fe39",
            "a00148a399f647acbcdbe2ae6a404114",
            "6a544a91c24947b39fb3b9da16bd18bd",
            "bedd90773b534f3ab1980cd57e8cf3dd",
            "7ee89de091fa4669a94be61d362bb249",
            "5b817fa5a8a94c0dbfbdfd1b4e9a66dc",
            "4299c0cd96154bcd87cc41fbd8a825d2",
            "267e00b0bc2840e9abf6c74a3eb1fae5",
            "6da58e1186e9468ca49b40980c03d50b",
            "d2bd7a7322d5449cbd932381869334de",
            "f7c985fb35464b889418bddf8e442033",
            "d57aefebc9314921882682e5e40f6e76",
            "2724c64ebb3d42deb938fba1b599cf70"
          ]
        },
        "outputId": "45efedaf-48c6-4ea8-9ce7-f7e0c0dcff9b"
      },
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "# base_model = TFBertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0b8624abc584f84a3f15315e30bd82b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b77a6dcf46ed46c8b956d9412efdb718",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f342d9ef4a934b7ab1c3be20e2b881c9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a544a91c24947b39fb3b9da16bd18bd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOmtab97aWYP"
      },
      "source": [
        "#Char CNN\n",
        "def charCNNProcessing():\n",
        "        #inputs = Input(shape=(self.input_size,), name='sent_input', dtype='int64')\n",
        "        inputs=layers.Input(shape=(max_input_length,),name=\"charcnn_input_ids\",dtype=tf.int32)\n",
        "        # Embedding layers\n",
        "        x = layers.Embedding(70, 128, input_length=max_input_length)(inputs)\n",
        "        charcnn=layers.Conv1D(filters=512,kernel_size=4, activation='relu',padding='same')\n",
        "        return charcnn\n",
        "        # Convolution layers\n",
        "        # convolution_output = []\n",
        "        # for num_filters, filter_width in self.conv_layers:\n",
        "        #     conv = Convolution1D(filters=num_filters,\n",
        "        #                          kernel_size=filter_width,\n",
        "        #                          activation='tanh',\n",
        "        #                          name='Conv1D_{}_{}'.format(num_filters, filter_width))(x)\n",
        "        #     pool = GlobalMaxPooling1D(name='MaxPoolingOverTime_{}_{}'.format(num_filters, filter_width))(conv)\n",
        "        #     convolution_output.append(pool)\n",
        "\n",
        "        # x = Concatenate()(convolution_output)\n",
        "        # Fully connected layers\n",
        "        # for fl in self.fully_connected_layers:\n",
        "        #     x = Dense(fl, activation='selu', kernel_initializer='lecun_normal')(x)\n",
        "        #     x = AlphaDropout(self.dropout_p)(x)\n",
        "        # Output layer\n",
        "        # predictions = Dense(self.num_of_classes, activation='softmax')(x)\n",
        "        # # Build and compile model\n",
        "        # model = Model(inputs=inputs, outputs=predictions)\n",
        "        # model.compile(optimizer=self.optimizer, loss=self.loss)\n",
        "        # self.model = model\n",
        "        # print(\"CharCNNKim model built: \")\n",
        "        # self.model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeR_L9Xfq1lP"
      },
      "source": [
        "def createToxicModelWithGivenBaseModel(max_input_length,base_model):\n",
        "    input_ids_layer = layers.Input(shape=(max_input_length,),name=\"encoder_input_ids\",dtype=tf.int32)\n",
        "    input_attention_mask_layer = layers.Input(shape=(max_input_length,),name=\"encoder_attention_mask\",dtype=tf.int32)\n",
        "    input_length = layers.Input(shape=(1,),name=\"length\",dtype=tf.int32)\n",
        "    base_model.trainable = True\n",
        "    base_model = base_model(input_ids_layer,attention_mask=input_attention_mask_layer,return_dict=True)\n",
        "\n",
        "    ### char CNN starts\n",
        "    embed = layers.Embedding(70, 128, input_length=max_input_length)(input_ids_layer)\n",
        "    charcnn=layers.Conv1D(filters=512,kernel_size=4, activation='relu',padding='same')(embed)\n",
        "    ### char CNN ends\n",
        "    \n",
        "    print(base_model.last_hidden_state.shape)\n",
        "    cnn1=layers.Conv1D(filters=512,kernel_size=4, activation='relu',padding='same')(base_model.last_hidden_state)\n",
        "    # maxpool1=layers.MaxPooling1D(5)(cnn1)\n",
        "    # #flatten1=layers.Flatten()(maxpool1)\n",
        "\n",
        "    # cnn2=layers.Conv1D(filters=256,kernel_size=4, activation='relu',padding='same')(maxpool1)\n",
        "    # maxpool2=layers.MaxPooling1D(4)(cnn2)\n",
        "    # #flatten2=layers.Flatten()(maxpool2)\n",
        "\n",
        "    # cnn3=layers.Conv1D(filters=128,kernel_size=3, activation='relu',padding='same')(maxpool2)\n",
        "    # maxpool3=layers.MaxPooling1D(3)(cnn3)\n",
        "    # #flatten3=layers.Flatten()(maxpool3)\n",
        "\n",
        "    # #merged = layers.Concatenate()([flatten1,flatten2,flatten3])\n",
        "    # #output=layers.Dense(400,activation=\"relu\")(merged)\n",
        "    # output=layers.Dropout(0.5)(maxpool3)\n",
        "    lstm = layers.LSTM(512,return_sequences=True)(base_model.last_hidden_state)\n",
        "    concat=layers.Concatenate()([cnn1,lstm,charcnn])\n",
        "    dense=layers.Dense(500,activation='relu')(concat)\n",
        "    drop=layers.Dropout(0.3)(dense)\n",
        "    output = layers.Dense(3,activation=\"linear\")(drop)\n",
        "    crf = CRFLayer()\n",
        "    output = crf(inputs=[output,input_length])\n",
        "    model = models.Model(inputs=[input_ids_layer,input_attention_mask_layer,input_length],outputs=output)\n",
        "    model.compile(optimizer=optimizers.Adam(learning_rate=3e-5),loss=crf.loss,metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3v8iA14by0o"
      },
      "source": [
        "max_length = 400"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TrD_b9_hFch"
      },
      "source": [
        "texts = toxic_span_dataset['text'].to_numpy()\n",
        "targets = createNEROutputs(texts,toxic_span_dataset['spans'],max_length,tokenizer)\n",
        "all_spans = toxic_span_dataset['spans'].to_numpy()\n",
        "result_test = []\n",
        "result_train = []\n",
        "kf = KFold(n_splits=5)\n",
        "train_test_indices = []\n",
        "for train_index,test_index in kf.split(texts):\n",
        "    \n",
        "    train_test_indices.append((train_index,test_index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lILr_oZ80wU1",
        "outputId": "c49a4752-725c-49a6-f251-19329895effb"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 29 21:04:41 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817,
          "referenced_widgets": [
            "49e27de49ef14e6f96403e1e8443c770",
            "fb20f4d75cbf422ab5230f01443ddbe7",
            "429fb63d0f0245e2896513a20c57ab17",
            "58bead0d77764c0eb4caaaa401dcc4dd",
            "ca4ec6d9598746f2bcf03f6f505d15a5",
            "7eed63001acf4a0cbccf423facda5e32",
            "36733087ecfb417b9532d2e111366c8a",
            "a6c10b28c501455c908a7ca10865e512",
            "24a5a5d581c047c2a89a8a3d59d1d966",
            "699d813cd6e04e2cb8333abce7582bd6",
            "3dee3ba038694fae86c9baf6ca7d24c4"
          ]
        },
        "id": "8iZstls4d923",
        "outputId": "54de39d9-70a0-4209-8bca-b7d3fded900c"
      },
      "source": [
        "train_index,test_index = train_test_indices.pop()\n",
        "print(train_index)\n",
        "print(test_index)\n",
        "x_train , x_test = list(texts[train_index]) , list(texts[test_index])\n",
        "y_train , y_test = targets[train_index] , targets[test_index]\n",
        "model = None\n",
        "base_model = None\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "base_model = TFRobertaModel.from_pretrained('roberta-base')\n",
        "model = createToxicModelWithGivenBaseModel(max_length,base_model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   0    1    2 ... 7949 7950 7951]\n",
            "[7952 7953 7954 ... 9936 9937 9938]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49e27de49ef14e6f96403e1e8443c770",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/627M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 400, 768)\n",
            "WARNING:tensorflow:From <ipython-input-13-fa344f941f1b>:68: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input_ids (InputLayer)  [(None, 400)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_attention_mask (InputLa [(None, 400)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_roberta_model (TFRobertaMode TFBaseModelOutputWit 124645632   encoder_input_ids[0][0]          \n",
            "                                                                 encoder_attention_mask[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 400, 512)     1573376     tf_roberta_model[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 400, 512)     2623488     tf_roberta_model[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 400, 1024)    0           conv1d[0][0]                     \n",
            "                                                                 lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 400, 500)     512500      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 400, 500)     0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 400, 3)       1503        dropout_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "length (InputLayer)             [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "crf_layer (CRFLayer)            (None, 400, 3)       9           dense_1[0][0]                    \n",
            "                                                                 length[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 129,356,508\n",
            "Trainable params: 129,356,508\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d32QjTEYJEJZ",
        "outputId": "18259e83-5355-41b2-a167-645bde684dad"
      },
      "source": [
        "train_data = createInputForNER(x_train,max_length,tokenizer)\n",
        "test_data = createInputForNER(x_test,max_length,tokenizer)\n",
        "spans_test = all_spans[test_index]\n",
        "spans_train = all_spans[train_index]\n",
        "model.fit(train_data,y_train,batch_size=16,epochs=2,callbacks=[callbacks.ModelCheckpoint(\"/content/drive/MyDrive/toxic span/final saved models/NER/roberta/LSTM_crf/ner\",save_weights_only=True)])\n",
        "preds = model.predict(test_data)\n",
        "indices = createIndicesForNERModel(preds,x_test,tokenizer)\n",
        "f1_toxic = avg_f1(indices,spans_test)\n",
        "print(\"test F1 = %f\"%(f1_toxic))\n",
        "result_test.append(f1_toxic)\n",
        "preds = model.predict(train_data)\n",
        "indices = createIndicesForNERModel(preds,x_train,tokenizer)\n",
        "f1_toxic = avg_f1(indices,spans_train)\n",
        "print(\"train F1 = %f\"%(f1_toxic))\n",
        "result_train.append(f1_toxic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "497/497 [==============================] - 601s 1s/step - loss: 9.7455 - accuracy: 0.1089\n",
            "Epoch 2/2\n",
            "497/497 [==============================] - 607s 1s/step - loss: 8.3756 - accuracy: 0.1092\n",
            "test F1 = 0.646134\n",
            "train F1 = 0.683065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDKqMaWkjoEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3390c505-52a9-49d4-ab28-4eca93cb39c0"
      },
      "source": [
        "train_index,test_index = train_test_indices.pop()\n",
        "x_train , x_test = list(texts[train_index]) , list(texts[test_index])\n",
        "y_train , y_test = targets[train_index] , targets[test_index]\n",
        "model = None\n",
        "base_model = None\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "base_model = TFRobertaModel.from_pretrained('roberta-base')\n",
        "model = createToxicModelWithGivenBaseModel(max_length,base_model)\n",
        "train_data = createInputForNER(x_train,max_length,tokenizer)\n",
        "test_data = createInputForNER(x_test,max_length,tokenizer)\n",
        "spans_test = all_spans[test_index]\n",
        "spans_train = all_spans[train_index]\n",
        "model.fit(train_data,y_train,batch_size=16,epochs=2,callbacks=[callbacks.ModelCheckpoint(\"/content/drive/MyDrive/toxic span/final saved models/NER/roberta/LSTM_crf/ner\",save_weights_only=True)])\n",
        "preds = model.predict(test_data)\n",
        "indices = createIndicesForNERModel(preds,x_test,tokenizer)\n",
        "f1_toxic = avg_f1(indices,spans_test)\n",
        "print(\"test F1 = %f\"%(f1_toxic))\n",
        "result_test.append(f1_toxic)\n",
        "preds = model.predict(train_data)\n",
        "indices = createIndicesForNERModel(preds,x_train,tokenizer)\n",
        "f1_toxic = avg_f1(indices,spans_train)\n",
        "print(\"train F1 = %f\"%(f1_toxic))\n",
        "result_train.append(f1_toxic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 400, 768)\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input_ids (InputLayer)  [(None, 400)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_attention_mask (InputLa [(None, 400)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_roberta_model (TFRobertaMode TFBaseModelOutputWit 124645632   encoder_input_ids[0][0]          \n",
            "                                                                 encoder_attention_mask[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 400, 512)     1573376     tf_roberta_model[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 400, 512)     2623488     tf_roberta_model[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 400, 1024)    0           conv1d[0][0]                     \n",
            "                                                                 lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 400, 500)     512500      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 400, 500)     0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 400, 3)       1503        dropout_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "length (InputLayer)             [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "crf_layer (CRFLayer)            (None, 400, 3)       9           dense_1[0][0]                    \n",
            "                                                                 length[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 129,356,508\n",
            "Trainable params: 129,356,508\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/2\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "497/497 [==============================] - 898s 2s/step - loss: 9.5830 - accuracy: 0.1114\n",
            "Epoch 2/2\n",
            "497/497 [==============================] - 904s 2s/step - loss: 8.1932 - accuracy: 0.1105\n",
            "test F1 = 0.658142\n",
            "train F1 = 0.701936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bgmycsljjo5B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ae02912-9273-42f8-c140-8c47f3d507af"
      },
      "source": [
        "train_index,test_index = train_test_indices.pop()\n",
        "x_train , x_test = list(texts[train_index]) , list(texts[test_index])\n",
        "y_train , y_test = targets[train_index] , targets[test_index]\n",
        "model = None\n",
        "base_model = None\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "base_model = TFRobertaModel.from_pretrained('roberta-base')\n",
        "model = createToxicModelWithGivenBaseModel(max_length,base_model)\n",
        "train_data = createInputForNER(x_train,max_length,tokenizer)\n",
        "test_data = createInputForNER(x_test,max_length,tokenizer)\n",
        "spans_test = all_spans[test_index]\n",
        "spans_train = all_spans[train_index]\n",
        "model.fit(train_data,y_train,batch_size=16,epochs=2,callbacks=[callbacks.ModelCheckpoint(\"/content/drive/MyDrive/toxic span/final saved models/NER/roberta/LSTM_crf/ner\",save_weights_only=True)])\n",
        "preds = model.predict(test_data)\n",
        "indices = createIndicesForNERModel(preds,x_test,tokenizer)\n",
        "f1_toxic = avg_f1(indices,spans_test)\n",
        "print(\"test F1 = %f\"%(f1_toxic))\n",
        "result_test.append(f1_toxic)\n",
        "preds = model.predict(train_data)\n",
        "indices = createIndicesForNERModel(preds,x_train,tokenizer)\n",
        "f1_toxic = avg_f1(indices,spans_train)\n",
        "print(\"train F1 = %f\"%(f1_toxic))\n",
        "result_train.append(f1_toxic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 400, 768)\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input_ids (InputLayer)  [(None, 400)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_attention_mask (InputLa [(None, 400)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_roberta_model (TFRobertaMode TFBaseModelOutputWit 124645632   encoder_input_ids[0][0]          \n",
            "                                                                 encoder_attention_mask[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 400, 512)     1573376     tf_roberta_model[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 400, 512)     2623488     tf_roberta_model[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 400, 1024)    0           conv1d[0][0]                     \n",
            "                                                                 lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 400, 500)     512500      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 400, 500)     0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 400, 3)       1503        dropout_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "length (InputLayer)             [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "crf_layer (CRFLayer)            (None, 400, 3)       9           dense_1[0][0]                    \n",
            "                                                                 length[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 129,356,508\n",
            "Trainable params: 129,356,508\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/2\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "497/497 [==============================] - 899s 2s/step - loss: 9.9140 - accuracy: 0.1119\n",
            "Epoch 2/2\n",
            "497/497 [==============================] - 903s 2s/step - loss: 8.5074 - accuracy: 0.1111\n",
            "test F1 = 0.648754\n",
            "train F1 = 0.687482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_wEmISWjpui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dd5da75-1bd4-4405-c5bf-d632d55dde99"
      },
      "source": [
        "train_index,test_index = train_test_indices.pop()\n",
        "x_train , x_test = list(texts[train_index]) , list(texts[test_index])\n",
        "y_train , y_test = targets[train_index] , targets[test_index]\n",
        "model = None\n",
        "base_model = None\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "base_model = TFRobertaModel.from_pretrained('roberta-base')\n",
        "model = createToxicModelWithGivenBaseModel(max_length,base_model)\n",
        "train_data = createInputForNER(x_train,max_length,tokenizer)\n",
        "test_data = createInputForNER(x_test,max_length,tokenizer)\n",
        "spans_test = all_spans[test_index]\n",
        "spans_train = all_spans[train_index]\n",
        "model.fit(train_data,y_train,batch_size=16,epochs=2,callbacks=[callbacks.ModelCheckpoint(\"/content/drive/MyDrive/toxic span/final saved models/NER/roberta/LSTM_crf/ner\",save_weights_only=True)])\n",
        "preds = model.predict(test_data)\n",
        "indices = createIndicesForNERModel(preds,x_test,tokenizer)\n",
        "f1_toxic = avg_f1(indices,spans_test)\n",
        "print(\"test F1 = %f\"%(f1_toxic))\n",
        "result_test.append(f1_toxic)\n",
        "preds = model.predict(train_data)\n",
        "indices = createIndicesForNERModel(preds,x_train,tokenizer)\n",
        "f1_toxic = avg_f1(indices,spans_train)\n",
        "print(\"train F1 = %f\"%(f1_toxic))\n",
        "result_train.append(f1_toxic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 400, 768)\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input_ids (InputLayer)  [(None, 400)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_attention_mask (InputLa [(None, 400)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_roberta_model (TFRobertaMode TFBaseModelOutputWit 124645632   encoder_input_ids[0][0]          \n",
            "                                                                 encoder_attention_mask[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 400, 512)     1573376     tf_roberta_model[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 400, 512)     2623488     tf_roberta_model[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 400, 1024)    0           conv1d[0][0]                     \n",
            "                                                                 lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 400, 500)     512500      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 400, 500)     0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 400, 3)       1503        dropout_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "length (InputLayer)             [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "crf_layer (CRFLayer)            (None, 400, 3)       9           dense_1[0][0]                    \n",
            "                                                                 length[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 129,356,508\n",
            "Trainable params: 129,356,508\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/2\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "497/497 [==============================] - 907s 2s/step - loss: 9.9481 - accuracy: 0.1113\n",
            "Epoch 2/2\n",
            "497/497 [==============================] - 911s 2s/step - loss: 8.3742 - accuracy: 0.1106\n",
            "test F1 = 0.673457\n",
            "train F1 = 0.691994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECUkmb47jr70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b19cca55-9632-4df4-ece6-458a3e0e3606"
      },
      "source": [
        "train_index,test_index = train_test_indices.pop()\n",
        "x_train , x_test = list(texts[train_index]) , list(texts[test_index])\n",
        "y_train , y_test = targets[train_index] , targets[test_index]\n",
        "model = None\n",
        "base_model = None\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "base_model = TFRobertaModel.from_pretrained('roberta-base')\n",
        "model = createToxicModelWithGivenBaseModel(max_length,base_model)\n",
        "train_data = createInputForNER(x_train,max_length,tokenizer)\n",
        "test_data = createInputForNER(x_test,max_length,tokenizer)\n",
        "spans_test = all_spans[test_index]\n",
        "spans_train = all_spans[train_index]\n",
        "model.fit(train_data,y_train,batch_size=16,epochs=2,callbacks=[callbacks.ModelCheckpoint(\"/content/drive/MyDrive/toxic span/final saved models/NER/roberta/LSTM_crf/ner\",save_weights_only=True)])\n",
        "preds = model.predict(test_data)\n",
        "indices = createIndicesForNERModel(preds,x_test,tokenizer)\n",
        "f1_toxic = avg_f1(indices,spans_test)\n",
        "print(\"test F1 = %f\"%(f1_toxic))\n",
        "result_test.append(f1_toxic)\n",
        "preds = model.predict(train_data)\n",
        "indices = createIndicesForNERModel(preds,x_train,tokenizer)\n",
        "f1_toxic = avg_f1(indices,spans_train)\n",
        "print(\"train F1 = %f\"%(f1_toxic))\n",
        "result_train.append(f1_toxic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 400, 768)\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input_ids (InputLayer)  [(None, 400)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_attention_mask (InputLa [(None, 400)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_roberta_model (TFRobertaMode TFBaseModelOutputWit 124645632   encoder_input_ids[0][0]          \n",
            "                                                                 encoder_attention_mask[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 400, 512)     1573376     tf_roberta_model[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 400, 512)     2623488     tf_roberta_model[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 400, 1024)    0           conv1d[0][0]                     \n",
            "                                                                 lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 400, 500)     512500      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 400, 500)     0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 400, 3)       1503        dropout_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "length (InputLayer)             [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "crf_layer (CRFLayer)            (None, 400, 3)       9           dense_1[0][0]                    \n",
            "                                                                 length[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 129,356,508\n",
            "Trainable params: 129,356,508\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/2\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "497/497 [==============================] - 897s 2s/step - loss: 11.2436 - accuracy: 0.1118\n",
            "Epoch 2/2\n",
            "497/497 [==============================] - 896s 2s/step - loss: 9.7985 - accuracy: 0.1119\n",
            "test F1 = 0.667302\n",
            "train F1 = 0.691865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTOstzX3hazN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c98043c7-b1a6-47e7-847a-059e343ba09c"
      },
      "source": [
        "f1_toxic = sum(result_test)/5\n",
        "print(\"final test F1 = %f\"%(f1_toxic))\n",
        "f1_toxic = sum(result_train)/5\n",
        "print(\"final train F1 = %f\"%(f1_toxic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final test F1 = 0.658758\n",
            "final train F1 = 0.691268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SUX33GhK87j"
      },
      "source": [
        "# train on random part of dataset to save a check point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94UPmXESLKuN"
      },
      "source": [
        "toxic_span_dataset = toxic_span_dataset.sample(frac=1)\n",
        "texts = toxic_span_dataset['text'].to_numpy()\n",
        "targets = createNEROutputs(texts,toxic_span_dataset['spans'],max_length,tokenizer)\n",
        "all_spans = toxic_span_dataset['spans'].to_numpy()\n",
        "result_test = []\n",
        "result_train = []\n",
        "kf = KFold(n_splits=5,shuffle=True)\n",
        "train_test_indices = []\n",
        "for train_index,test_index in kf.split(texts):\n",
        "    train_test_indices.append((train_index,test_index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvQAzBq2LHuf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9824cd82-ea9e-4ee3-fa9e-5190219a60d8"
      },
      "source": [
        "train_index,test_index = train_test_indices.pop()\n",
        "x_train , x_test = list(texts[train_index]) , list(texts[test_index])\n",
        "y_train , y_test = targets[train_index] , targets[test_index]\n",
        "model = None\n",
        "base_model = None\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "base_model = TFRobertaModel.from_pretrained('roberta-base')\n",
        "model = createToxicModelWithGivenBaseModel(max_length,base_model)\n",
        "train_data = createInputForNER(x_train,max_length,tokenizer)\n",
        "test_data = createInputForNER(x_test,max_length,tokenizer)\n",
        "spans_test = all_spans[test_index]\n",
        "spans_train = all_spans[train_index]\n",
        "model.fit(train_data,y_train,batch_size=16,epochs=2,callbacks=[callbacks.ModelCheckpoint(\"/content/drive/MyDrive/toxic span/final saved models/NER/roberta/LSTM_crf/ner\",save_weights_only=True)])\n",
        "preds = model.predict(test_data)\n",
        "indices = createIndicesForNERModel(preds,x_test,tokenizer)\n",
        "f1_toxic = avg_f1(indices,spans_test)\n",
        "print(\"test F1 = %f\"%(f1_toxic))\n",
        "result_test.append(f1_toxic)\n",
        "preds = model.predict(train_data)\n",
        "indices = createIndicesForNERModel(preds,x_train,tokenizer)\n",
        "f1_toxic = avg_f1(indices,spans_train)\n",
        "print(\"train F1 = %f\"%(f1_toxic))\n",
        "result_train.append(f1_toxic)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
            "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 400, 768)\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input_ids (InputLayer)  [(None, 400)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_attention_mask (InputLa [(None, 400)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_roberta_model (TFRobertaMode TFBaseModelOutputWit 124645632   encoder_input_ids[0][0]          \n",
            "                                                                 encoder_attention_mask[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 400, 512)     1573376     tf_roberta_model[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 400, 512)     2623488     tf_roberta_model[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 400, 1024)    0           conv1d[0][0]                     \n",
            "                                                                 lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 400, 500)     512500      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 400, 500)     0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 400, 3)       1503        dropout_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "length (InputLayer)             [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "crf_layer (CRFLayer)            (None, 400, 3)       9           dense_1[0][0]                    \n",
            "                                                                 length[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 129,356,508\n",
            "Trainable params: 129,356,508\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/2\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
            "497/497 [==============================] - 612s 1s/step - loss: 9.7891 - accuracy: 0.1112\n",
            "Epoch 2/2\n",
            "405/497 [=======================>......] - ETA: 1:51 - loss: 8.2878 - accuracy: 0.1112"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-4d76ee3cbe7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mspans_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_spans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mspans_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_spans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/toxic span/final saved models/NER/roberta/LSTM_crf/ner\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_weights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateIndicesForNERModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    340\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}